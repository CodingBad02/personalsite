(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[327],{9182:function(e,a,r){(window.__NEXT_P=window.__NEXT_P||[]).push(["/projects",function(){return r(4505)}])},1021:function(e,a,r){"use strict";r.d(a,{Z:function(){return x}});var t=r(5893),i=r(7294),n=r(1664),s=r.n(n),o=r(1163),l=r(8447),c=r(4052),d=r(1526),h=r(3495),m=()=>{let[e,a]=(0,i.useState)(!1),r=(0,o.useRouter)(),{theme:n,toggleTheme:m}=(0,l.F)(),[p,x]=(0,i.useState)(!1);(0,i.useEffect)(()=>{let e=()=>{window.scrollY>20?x(!0):x(!1)};return window.addEventListener("scroll",e),()=>{window.removeEventListener("scroll",e)}},[]);let g=[{name:"Home",path:"/"},{name:"About",path:"/about"},{name:"Experience",path:"/experience"},{name:"Projects",path:"/projects"},{name:"Publications",path:"/publications"},{name:"Skills",path:"/skills"},{name:"Contact",path:"/contact"}];return(0,t.jsxs)("header",{className:"fixed w-full z-50 transition-all duration-300 ".concat(p?"py-3 glassmorphism":"py-5 bg-transparent"),children:[(0,t.jsx)("div",{className:"container mx-auto px-4 md:px-6",children:(0,t.jsxs)("nav",{className:"flex justify-between items-center",children:[(0,t.jsx)(s(),{href:"/",className:"text-2xl font-bold gradient-text",children:"Manjunathan"}),(0,t.jsxs)("div",{className:"hidden md:flex space-x-8 items-center",children:[g.map(e=>(0,t.jsx)(s(),{href:e.path,className:"nav-link ".concat(r.pathname===e.path?"active":""),children:e.name},e.path)),(0,t.jsx)("button",{onClick:m,className:"p-2 rounded-full hover:bg-gray-200 dark:hover:bg-gray-700 transition-colors","aria-label":"Toggle theme",children:"dark"===n?(0,t.jsx)(c.kXG,{className:"h-5 w-5"}):(0,t.jsx)(c.wOW,{className:"h-5 w-5"})})]}),(0,t.jsxs)("div",{className:"flex md:hidden items-center space-x-4",children:[(0,t.jsx)("button",{onClick:m,className:"p-2 rounded-full hover:bg-gray-200 dark:hover:bg-gray-700 transition-colors","aria-label":"Toggle theme",children:"dark"===n?(0,t.jsx)(c.kXG,{className:"h-5 w-5"}):(0,t.jsx)(c.wOW,{className:"h-5 w-5"})}),(0,t.jsx)("button",{onClick:()=>{a(!e)},className:"p-2 rounded-lg hover:bg-gray-200 dark:hover:bg-gray-700 transition-colors","aria-label":"Toggle menu",children:e?(0,t.jsx)(c.q5L,{className:"h-6 w-6"}):(0,t.jsx)(c.cur,{className:"h-6 w-6"})})]})]})}),(0,t.jsx)(d.M,{children:e&&(0,t.jsx)(h.E.div,{initial:{opacity:0,height:0},animate:{opacity:1,height:"auto"},exit:{opacity:0,height:0},transition:{duration:.3},className:"md:hidden glassmorphism border-t border-gray-200 dark:border-gray-700",children:(0,t.jsx)("div",{className:"container mx-auto px-4 py-4 space-y-2",children:g.map(e=>(0,t.jsx)(s(),{href:e.path,className:"block py-3 px-4 rounded-md ".concat(r.pathname===e.path?"bg-primary-light/10 dark:bg-primary-dark/10 text-primary-light dark:text-primary-dark font-medium":"hover:bg-gray-100 dark:hover:bg-gray-800 transition-colors"),onClick:()=>a(!1),children:e.name},e.path))})})})]})},p=()=>{let e=new Date().getFullYear();return(0,t.jsx)("footer",{className:"bg-surface-light dark:bg-surface-dark py-8",children:(0,t.jsxs)("div",{className:"container mx-auto px-4",children:[(0,t.jsxs)("div",{className:"flex flex-col md:flex-row justify-between items-center",children:[(0,t.jsxs)("div",{className:"mb-6 md:mb-0",children:[(0,t.jsx)("div",{className:"text-2xl font-bold gradient-text mb-2",children:"Manjunathan R"}),(0,t.jsx)("p",{className:"text-gray-600 dark:text-gray-400",children:"ML Engineer & Researcher"})]}),(0,t.jsxs)("div",{className:"flex flex-wrap justify-center gap-8 mb-6 md:mb-0",children:[(0,t.jsx)(s(),{href:"/",className:"hover:text-primary-light dark:hover:text-primary-dark transition-colors",children:"Home"}),(0,t.jsx)(s(),{href:"/about",className:"hover:text-primary-light dark:hover:text-primary-dark transition-colors",children:"About"}),(0,t.jsx)(s(),{href:"/experience",className:"hover:text-primary-light dark:hover:text-primary-dark transition-colors",children:"Experience"}),(0,t.jsx)(s(),{href:"/projects",className:"hover:text-primary-light dark:hover:text-primary-dark transition-colors",children:"Projects"}),(0,t.jsx)(s(),{href:"/contact",className:"hover:text-primary-light dark:hover:text-primary-dark transition-colors",children:"Contact"})]}),(0,t.jsxs)("div",{className:"flex space-x-4",children:[(0,t.jsx)("a",{href:"https://github.com/CodingBad02",target:"_blank",rel:"noopener noreferrer",className:"text-gray-600 dark:text-gray-400 hover:text-primary-light dark:hover:text-primary-dark transition-colors","aria-label":"GitHub",children:(0,t.jsx)(c.uOf,{className:"h-6 w-6"})}),(0,t.jsx)("a",{href:"https://linkedin.com/in/manjunathan-r",target:"_blank",rel:"noopener noreferrer",className:"text-gray-600 dark:text-gray-400 hover:text-primary-light dark:hover:text-primary-dark transition-colors","aria-label":"LinkedIn",children:(0,t.jsx)(c.qOw,{className:"h-6 w-6"})}),(0,t.jsx)("a",{href:"mailto:manjunathan.ai02@gmail.com",className:"text-gray-600 dark:text-gray-400 hover:text-primary-light dark:hover:text-primary-dark transition-colors","aria-label":"Email",children:(0,t.jsx)(c.Imn,{className:"h-6 w-6"})})]})]}),(0,t.jsx)("div",{className:"mt-8 pt-6 border-t border-gray-200 dark:border-gray-700 text-center text-gray-500 dark:text-gray-400",children:(0,t.jsxs)("p",{children:["\xa9 ",e," Manjunathan Radhakrishnan. All rights reserved."]})})]})})},x=e=>{let{children:a}=e;return(0,t.jsxs)("div",{className:"flex flex-col min-h-screen",children:[(0,t.jsx)(m,{}),(0,t.jsx)("main",{className:"flex-grow",children:a}),(0,t.jsx)(p,{})]})}},4505:function(e,a,r){"use strict";r.r(a),r.d(a,{default:function(){return u}});var t=r(5893),i=r(7294),n=r(9008),s=r.n(n),o=r(1021),l=r(3495),c=r(1526),d=r(8357),h=r(4052),m=r(8885),p=e=>{let{project:a,index:r}=e,{title:n,description:s,image:o,technologies:p,githubLink:x,demoLink:g,longDescription:u}=a,[f,y]=(0,i.useState)(!1),[b,j]=(0,d.YD)({triggerOnce:!0,threshold:.1}),v=()=>{y(!f)};return(0,t.jsxs)(l.E.div,{ref:b,initial:{opacity:0,y:20},animate:j?{opacity:1,y:0}:{},transition:{duration:.5,delay:.1*r},className:"card group h-full flex flex-col",children:[(0,t.jsxs)("div",{className:"relative overflow-hidden h-48",children:[(0,t.jsx)("img",{src:o||"/images/projects/placeholder.jpg",alt:n,className:"w-full h-full object-cover transition-transform duration-500 group-hover:scale-110"}),(0,t.jsx)("div",{className:"absolute inset-0 bg-gradient-to-t from-black/60 to-transparent opacity-0 group-hover:opacity-100 transition-opacity duration-300 flex items-end",children:(0,t.jsxs)("div",{className:"p-4 w-full flex justify-end space-x-3",children:[x&&(0,t.jsx)("a",{href:x,target:"_blank",rel:"noopener noreferrer",className:"text-white hover:text-primary-light dark:hover:text-primary-dark transition-colors","aria-label":"View GitHub Repository",children:(0,t.jsx)(h.uOf,{className:"h-6 w-6"})}),g&&(0,t.jsx)("a",{href:g,target:"_blank",rel:"noopener noreferrer",className:"text-white hover:text-primary-light dark:hover:text-primary-dark transition-colors","aria-label":"Read More About this!",children:(0,t.jsx)(h.AlO,{className:"h-6 w-6"})})]})})]}),(0,t.jsxs)("div",{className:"p-6 flex-grow flex flex-col cursor-pointer",onClick:v,children:[(0,t.jsxs)("div",{className:"flex justify-between items-start",children:[(0,t.jsx)("h3",{className:"text-xl font-bold mb-3 pr-6",children:n}),(0,t.jsx)("button",{className:"p-2 rounded-full hover:bg-gray-100 dark:hover:bg-gray-700 transition-colors",onClick:e=>{e.stopPropagation(),v()},"aria-label":f?"Collapse":"Expand",children:f?(0,t.jsx)(h.rH8,{className:"h-5 w-5"}):(0,t.jsx)(h.bTu,{className:"h-5 w-5"})})]}),(0,t.jsx)("p",{className:"text-gray-600 dark:text-gray-400 mb-4 flex-grow",children:s}),(0,t.jsx)("div",{className:"flex flex-wrap gap-2 mt-auto",children:p.map((e,a)=>(0,t.jsx)("span",{className:"px-3 py-1 text-sm bg-gray-100 dark:bg-gray-700 rounded-full",children:e},a))}),(0,t.jsx)(c.M,{children:f&&u&&(0,t.jsxs)(l.E.div,{initial:{height:0,opacity:0},animate:{height:"auto",opacity:1},exit:{height:0,opacity:0},transition:{duration:.3},className:"overflow-hidden mt-4 pt-4 border-t border-gray-200 dark:border-gray-700",children:[(0,t.jsx)("h4",{className:"font-medium mb-2",children:"Project Details"}),(0,t.jsx)("div",{className:"prose dark:prose-invert",children:(0,t.jsx)(m.UG,{children:u})}),(0,t.jsxs)("div",{className:"flex space-x-4 mt-4",children:[x&&(0,t.jsxs)("a",{href:x,target:"_blank",rel:"noopener noreferrer",className:"flex items-center text-primary-light dark:text-primary-dark hover:underline",onClick:e=>e.stopPropagation(),children:[(0,t.jsx)(h.uOf,{className:"mr-2"}),"View Code"]}),g&&(0,t.jsxs)("a",{href:g,target:"_blank",rel:"noopener noreferrer",className:"flex items-center text-primary-light dark:text-primary-dark hover:underline",onClick:e=>e.stopPropagation(),children:[(0,t.jsx)(h.AlO,{className:"mr-2"}),"Read More"]})]})]})})]})]})},x=r(8464);let g=[{id:1,title:"TrainConv Framework",description:"A distributed training framework on PyTorch and TensorFlow with configuration-based pipelines and automated orchestration.",longDescription:(0,x.C)("\n    • **TrainConv** is an MSD wrapper built around PyTorch for training machine learning models.\n    \n    • **Purpose**:\n      - Provides a standardized, simplified, and config-driven approach for building models.\n      - Reduces boilerplate code and avoids repetitive integrations.\n    \n    • **Modular Design**:\n      - Supports easy addition of modules such as loss functions, preprocessing pipelines, and custom data loaders.\n    \n    • **Hyperparameter Optimization**:\n      - Integrated with the **Tune** library, enabling efficient hyperparameter searches.\n    \n    • **Local Setup**:\n      - Can run locally using a virtual environment (`virtualenv`).\n      - Dependencies defined in `requirements.txt`.\n    \n    • **Visualization & Monitoring**:\n      - Utilizes **TensorBoard** for visualizing training metrics.\n    "),technologies:["PyTorch","TensorFlow","Distributed Computing","Tune"],githubLink:"https://github.com/CodingBad02/trainconv",demoLink:""},{id:2,title:"DeepGait",description:"An IoT-based intelligent gait analysis system using a 6-axis IMU, force sensors, and AWS integration.",longDescription:(0,x.C)("\n      DeepGait combines hardware and AI to create a comprehensive gait analysis platform. The system uses custom-designed insoles with embedded force sensors and a 6-axis IMU to capture detailed movement data. Our deep learning pipeline processes this data to extract gait parameters, detect anomalies, and provide actionable insights for physical therapy and rehabilitation. The cloud backend on AWS enables real-time monitoring, historical analysis, and personalized recommendations for users and healthcare providers.\n    "),technologies:["Deep Learning","IoT","AWS","Embedded Systems","Time-Series Analysis"],githubLink:"https://github.com/CodingBad02/deepgait",demoLink:"https://www.covaichronicle.com/english/contentview/forge30822"},{id:3,title:"GCN for Pandemic Prediction",description:"Graph convolutional networks for predicting state-wise COVID-19 incidence with up to 85.3% accuracy.",longDescription:(0,x.C)("\n      This research project leverages the power of Graph Convolutional Networks (GCNs) to model and predict the spread of COVID-19 across Indian states. By representing states as nodes in a graph with edges defined by geographic adjacency and transportation links, our model captures the complex spatial dependencies in disease transmission. The model incorporates demographic, healthcare, and mobility data to achieve 85.3% prediction accuracy, outperforming traditional time-series and statistical approaches. The research was published in IEEE AISP 2022 and has implications for pandemic preparedness and resource allocation.\n    "),technologies:["GCN","Graph Neural Networks","PyTorch Geometric","Spatiotemporal Modeling"],githubLink:"https://github.com/sid-sr/covid-19-gnn",demoLink:""},{id:4,title:"Real-time Ship Detection",description:"A modified YOLOV3 architecture for ship detection in synthetic radar images with high accuracy and performance.",longDescription:(0,x.C)("\n      This computer vision project addresses the challenge of detecting ships in Synthetic Aperture Radar (SAR) images under various conditions. We developed a modified YOLOv3 architecture optimized for SAR imagery, incorporating attention mechanisms and custom anchor boxes to improve detection accuracy. The system achieves 81.02% mAP and near 100% accuracy in element detection while maintaining real-time performance at 30+ FPS on standard GPU hardware. The solution is designed to integrate with maritime surveillance systems and can operate in adverse weather conditions where optical systems fail.\n    "),technologies:["YOLOv3","Darknet","Computer Vision","Object Detection","SAR Image Processing"],githubLink:"",demoLink:""}];var u=()=>(0,t.jsxs)(o.Z,{children:[(0,t.jsx)(s(),{children:(0,t.jsx)("title",{children:"Projects | Manjunathan Radhakrishnan"})}),(0,t.jsxs)("section",{className:"py-20 container mx-auto px-4",children:[(0,t.jsx)("h1",{className:"text-4xl font-bold mb-8",children:"Projects"}),(0,t.jsx)("div",{className:"grid grid-cols-1 md:grid-cols-2 gap-8",children:g.map(e=>(0,t.jsx)(p,{project:e},e.id))})]})]})}},function(e){e.O(0,[152,789,411,888,774,179],function(){return e(e.s=9182)}),_N_E=e.O()}]);